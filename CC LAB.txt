EXPERIMENT 1 EC2


1.Creation of Amazon EC2 Instances (Linux and Windows) and Establishing Secure Connections Using SSH from Local Machine, PuTTY (.pem & .ppk), AWS CloudShell, and Remote Desktop Protocol (RDP)
________________________________________
üßæ PREREQUISITES
Make sure you have:
‚Ä¢	‚úÖ EC2 Ubuntu instance running
‚Ä¢	‚úÖ .ppk private key file
‚Ä¢	‚úÖ PuTTY installed (Windows)-- https://putty.org/index.html   (INSTALL FIRST ONE)
________________________________________
üîπ STEP 1: Check Security Group
Go to EC2 ‚Üí Security Groups ‚Üí Inbound rules
Ensure this rule exists:
Type: SSH
Port: 22
Source: My IP
‚ùå If SSH is blocked ‚Üí connection will fail
________________________________________
üîπ STEP 2: Open PuTTY
1.	Launch PuTTY
2.	In Session screen:
Host Name (or IP address): EC2‚ÄîCONNECT‚ÄîCOPY (DNS NAME)
ubuntu@<PUBLIC-IP>
Example:
ubuntu@3.110.xxx.xxx
________________________________________
üîπ STEP 3: Attach the .ppk Key
In PuTTY left menu, go to:
Connection ‚Üí SSH ‚Üí Auth ‚Üí Credentials
1.	Click Browse
2.	Select your .ppk file
3.	Click Open
________________________________________
üîπ STEP 4: Connect to EC2
Click Open
‚Ä¢	First time ‚Üí click Yes (security alert)
‚Ä¢	PuTTY will log in automatically as:
ubuntu
üéâ You are now connected to your Ubuntu EC2 instance
________________________________________
üß™ VERIFY CONNECTION
Run:
whoami
Output should be:
Ubuntu

________________________________________
 Connect EC2 Ubuntu Instance Using PuTTY (Windows) ---USING PEM KEYPAIR
________________________________________
PREREQUISITES
You must have:
‚Ä¢	‚úÖ EC2 Ubuntu instance running
‚Ä¢	‚úÖ Public IPv4 address (or Elastic IP)
‚Ä¢	‚úÖ Key pair (.pem file) used while launching EC2
‚Ä¢	‚úÖ PuTTY & PuTTYgen installed
üëâ Download PuTTY:
https://www.putty.org
________________________________________
üîπ STEP 1: Convert .pem to .ppk using PuTTYgen
PuTTY cannot use .pem directly.
Steps:
1.	Open PuTTYgen
2.	Click Load
3.	Select your .pem file
(change file type to All Files)
4.	Click Open
5.	Click Save private key
6.	Save as keyname.ppk
‚úî Conversion done
________________________________________
üîπ STEP 2: Get EC2 Public IP
Go to:
AWS Console ‚Üí EC2 ‚Üí Instances---CONNECT ‚ÄìCOPY DNS NAME
________________________________________
üîπ STEP 3: Configure PuTTY
1Ô∏è‚É£ Open PuTTY
Session:
‚Ä¢	Host Name (or IP address): dns name
________________________________________
2Ô∏è‚É£ Load Private Key
Go to:
Connection ‚Üí SSH ‚Üí Auth ‚Üí Credentials
‚Ä¢	Click Browse
‚Ä¢	Select your .ppk file
________________________________________
üîπ STEP 4: Connect
Click Open
‚Ä¢	First time ‚Üí click Yes (security alert)
‚Ä¢	Login happens automatically as:
ubuntu
üéâ You are now connected to Ubuntu EC2
________________________________________
üß™ VERIFY CONNECTION
Run:
whoami
Output:
ubuntu
________________________________________
):
________________________________________
Connecting to EC2 Using AWS CloudShell
1.	Create the EC2 instance using a key pair (.pem).
2.	Log in to AWS Console and click on the CloudShell icon (terminal icon on the top-right).
3.	Once CloudShell opens, go to AWS Services ‚Üí EC2.
4.	Select your EC2 instance and click Connect.
5.	Choose the SSH client tab.
6.	Copy the ssh -i command shown there.
7.	Paste the command in CloudShell and try to run it.
‚ùå It will fail with an error like:
‚Äúkey pair is not available / no such file or directory‚Äù
(because the key file is not yet in CloudShell).
8.	Now, in CloudShell, click on the ‚Äú+‚Äù (Actions) icon on the right side.
9.	Select Upload file and upload the key pair (.pem) from your local machine.
10.	After upload, copy the ssh -i command again from EC2 ‚Üí Connect ‚Üí SSH client.
11.	Paste and execute the command in CloudShell.
12.	‚úÖ You are now successfully connected to the EC2 instance.
________________________________________
Step-by-Step: Create Windows EC2 Instance and Connect via RDP
Step 1: Launch a Windows EC2 Instance
1.	Log in to your AWS Management Console.
2.	Navigate to EC2 ‚Üí Instances ‚Üí Launch Instances.
3.	Select an Amazon Machine Image (AMI):
o	Choose a Windows Server AMI (e.g., Windows Server 2019 or 2022).
4.	Choose an Instance Type (e.g., t2.micro for free tier or as per your requirement).
5.	Configure Instance Details as needed.
6.	Add Storage if required (default is usually sufficient).
7.	Configure Security Group:
o	Ensure RDP port 3389 is allowed.
o	Source can be My IP (for security) or a wider range if needed.
8.	Select or create a new Key Pair:
o	Download the .pem file (keep it safe; it‚Äôs needed to decrypt the password).
9.	Click Launch Instance.
________________________________________
Step 2: Get the Public DNS / IP
1.	After the instance is running, go to EC2 ‚Üí Instances.
2.	Select your instance and note the Public DNS (IPv4) or Public IP.
________________________________________
Step 3: Retrieve the Windows Administrator Password
1.	Select your instance ‚Üí Click Connect ‚Üí RDP Client.
2.	Click Get Password.
3.	Upload your Key Pair (.pem) file.
4.	Click Decrypt Password.
5.	Copy the Administrator password shown.
________________________________________
Step 4: Connect via RDP
1.	On your local Windows machine, open Remote Desktop Connection (mstsc).
2.	In the Computer field, enter the Public DNS or IP address of the EC2 instance.
3.	Click Connect.
4.	In the login prompt:
o	Username: Administrator
o	Password: Paste the decrypted password from Step 3.
5.	Click OK.
________________________________________
Step 5: You‚Äôre connected
‚Ä¢	Your Windows EC2 instance desktop should appear.
‚Ä¢	You can now use it as a normal Windows machine.













EXPERIMENT 2 EBS

Week-2
1.	a) Create and attach an EBS volume to an EC2 instance, and 
b)	scale the instance by increasing CPU and RAM by changing the instance type.
2.Attach and permanently mount an EBS volume to a Linux EC2 instance to ensure data persistence across reboots.
3. Create a snapshot of the attached EBS volume and use it to create and attach a new volume to an EC2 instance in another AWS region.
________________________________________
1.	a) Create and attach an EBS volume to an EC2 instance, and 
b)	scale the instance by increasing CPU and RAM by changing the instance type.

a)	Creating  and attaching  an EBS volume to an EC2 instance
Step 1: Create a New EBS Volume
Open the EC2 Dashboard.
From the left-hand menu, select Volumes under Elastic Block Store (EBS).
Click Create Volume.
Choose:
Volume type (gp3/gp2)
Size of the volume
Availability Zone (must be the same as the EC2 instance)
Click Create Volume.
________________________________________
Step 2: Attach the EBS Volume to the Existing EC2 Instance
In the Volumes section, select the newly created volume.
Click Actions ‚Üí Attach Volume.
Select the target EC2 instance from the list.
Specify the device name (example: /dev/xvdf).
Click Attach.
________________________________________
Step 3: Verify the Volume on the EC2 Instance
Connect to the EC2 instance using SSH.
Check the attached disks:
lsblk
Identify the new volume (e.g., /dev/xvdf).

Note: Ensure that the EBS volume and the EC2 instance belong to the same Availability Zone, as cross-AZ attachment is not supported.
________________________________________

b)Procedure: increasing/decreasing  of CPU and RAM
   Step 1.  - Navigate to the EC2 dashboard.
   Step 2. - Stop the EC2 instance associated with the EBS volume.
 	Step 3.  - Click "Actions" and then‚Äîinstance settings‚Äîchange the instance type"Modify Volume".
  	Step 4. -Increase/ decrease the size or change the volume type to a higher performance specification.
   	Step 5. - Click "Modify" to apply the changes.
   	Step 6:  Now the start the machine you see with increase /decrease of size and performance
________________________________________
2.Attach and permanently mount an EBS volume to a Linux EC2 instance to ensure data persistence across reboots.
Objective
Attach an additional EBS volume (example: 20‚ÄØGB) to a Linux EC2 instance and mount it using the system default device names that appear on modern EC2 (Nitro) instances.
Note: Although you select a device name like /dev/xvdf in the AWS Console, the OS typically shows the disk as NVMe devices such as /dev/nvme1n1 and partitions as /dev/nvme1n1p1.
________________________________________
Step 1: Create an EBS Volume
1.	Log in to AWS Management Console
2.	Go to EC2 ‚Üí Volumes
3.	Click Create volume
4.	Choose:
o	Volume type: gp3 (recommended)
o	Size: 20‚ÄØGB (example)
o	Availability Zone: Same AZ as the EC2 instance
5.	Click Create volume
________________________________________
Step 2: Attach the EBS Volume to EC2
1.	Select the newly created EBS volume
2.	Click Actions ‚Üí Attach volume
3.	Choose:
o	Instance: Your Linux EC2 instance
o	Device name (console level): /dev/xvdf
4.	Click Attach
Internally, Linux will expose this as an NVMe device (for example /dev/nvme1n1).
________________________________________
Step 3: Connect to the EC2 Instance
Connect using SSH:
ssh -i key.pem ec2-user@<public-ip>
________________________________________
Step 4: Verify the Attached Disk
List all block devices:
lsblk
You will typically see:
‚Ä¢	Root volume: /dev/nvme0n1 (with partitions like nvme0n1p1)
‚Ä¢	New EBS volume: /dev/nvme1n1 (no partition yet)
Check filesystem information:
lsblk -fs
________________________________________
Step 5: Create a Partition on the New Volume
Create a partition on the unpartitioned disk:
fdisk /dev/nvme1n1
Inside fdisk:
‚Ä¢	Press m ‚Üí Help menu
‚Ä¢	Press n ‚Üí New partition
‚Ä¢	Press p ‚Üí Primary partition
‚Ä¢	Press Enter ‚Üí Default partition number
‚Ä¢	Press Enter ‚Üí Default first sector
‚Ä¢	Press Enter ‚Üí Default last sector (use full disk)
‚Ä¢	Press w ‚Üí Write changes and exit
Notify the kernel:
partprobe
________________________________________
Step 6: Verify the New Partition
lsblk -fs
You should now see:
‚Ä¢	/dev/nvme1n1p1
________________________________________
Step 7: Format the Partition
Format the partition with XFS filesystem:
mkfs.xfs /dev/nvme1n1p1
Verify:
lsblk -fs
________________________________________
Step 8: Create a Mount Directory
mkdir /mnt/archana
________________________________________
Step 9: Mount the Volume
mount /dev/nvme1n1p1 /mnt/archana
Verify:
df -h
________________________________________
Step 10: Make the Mount Persistent (fstab)
Get the UUID:
blkid /dev/nvme1n1p1
Example output:
UUID="f1e294e6-7657-4761-bba5-bb2d0eab3936"
Edit /etc/fstab:
nano /etc/fstab
Add this line at the end:
UUID=f1e294e6-7657-4761-bba5-bb2d0eab3936   /mnt/archana   xfs   defaults,nofail   0   0
Save and exit.
Test the entry:
mount -a
navigate to cd /mnt/archana
create the files here
touch f1
________________________________________
Step 11: Verify Persistence
1.	Reboot the instance:
reboot
2.	Reconnect and check:
df -h
‚û°Ô∏è The volume should mount automatically.
________________________________________
Step 12: Detach and Reattach Volume (Data Recovery Scenario)
Detach the Volume
‚Ä¢	EC2 ‚Üí Volumes ‚Üí Select volume
‚Ä¢	Actions ‚Üí Detach volume
Attach to Another EC2 Instance (Same AZ)
1.	Attach the volume to a new instance
2.	Log in to the new instance
3.	Create mount directory:
mkdir /mnt/archana
4.	Mount the existing partition:
mount /dev/nvme1n1p1 /mnt/archana
‚úÖ All previously stored data will be available.
________________________________________
Summary Flow
Create Volume ‚Üí Attach ‚Üí lsblk ‚Üí fdisk ‚Üí mkfs ‚Üí mkdir ‚Üí mount ‚Üí fstab ‚Üí reboot
________________________________________

3. Create a snapshot of the attached EBS volume and use it to create and attach a new volume to an EC2 instance in another AWS region.
Attaching Volumes across regions of EC2 using the snapshot
To create a snapshot of an EBS volume and attach it to an instance in another region in AWS, you'll need to follow these steps:

Step 1. Create a Snapshot:
   a. Sign in to the AWS Management Console.
   b. Navigate to the EC2 Dashboard.
   c. Click on "Volumes" in the left-hand navigation pane.
   d. Select the EBS volume you want to create a snapshot of.
   e. Click on the "Actions" dropdown menu above the volume list and select "Create Snapshot."
   f. Provide a name and description for the snapshot.
   g. Click on the "Create Snapshot" button to initiate the snapshot creation process.

Step 2. Copy the Snapshot to Another Region:
   a. Once the snapshot is created, go to the "Snapshots" section in the EC2 Dashboard.
   b. Select the snapshot you just created.
   c. Click on the "Actions" dropdown menu above the snapshot list and select "Copy Snapshot."
   d. Choose the destination region where you want to copy the snapshot.
   e. Click on the "Copy Snapshot" button to initiate the copy process. This may take some time depending on the size of the snapshot and the network speed.

Step 3. Monitor the Snapshot Copy Progress:
   a. You can monitor the progress of the snapshot copy by navigating to the "Snapshots" section in the EC2 Dashboard of the source region.
   b. Look for the snapshot you copied and check its status. It will change from "pending" to "completed" once the copy process is finished.

Step 4. Switch to the Destination Region:
a.	Use the region selector in the top-right corner of the AWS Management Console to switch to the destination region where you copied the snapshot.

Step 5. Create a Volume from the Snapshot:
   a. In the EC2 Dashboard of the destination region, go to the "Snapshots" section.
   b. Find the snapshot you copied from the source region.
   c. Click on the snapshot, then click on the "Actions" dropdown menu and select "Create Volume."
   d. Configure the volume settings, such as volume type, size, and availability zone.
   e. Click on the "Create Volume" button to create the volume from the snapshot.

Step 6. Create the ec2 instance & Attach the Volume to an Instance:
   a. Once the volume is created, navigate to the "Volumes" section in the EC2 Dashboard.
   b. Find the newly created volume and select it.
   c. Click on the "Actions" dropdown menu and select "Attach Volume."
   D  the EC2 instance to which you want to attach the volume and specify the device name.
   e. Click on the "Attach" button to attach the volume to the instance.

We have created a snapshot of an EBS volume, copied it to another region, created a volume from the snapshot, and attached it to an instance in the destination region.








EXPERIMENT 3  EFS

Elastic File Storage
Amazon Elastic File System (EFS) is a scalable and fully managed file storage service provided by Amazon Web Services (AWS). It allows you to create and configure file systems that can be accessed concurrently from multiple EC2 instances, providing a highly available and scalable storage solution for your applications and workloads.
 
Amazon EFS supports for only  Amazon Linux instance:
Step 1: Launching EC2 Instances
1. Sign in to AWS Management Console.
2. Go to the EC2 dashboard.
3. Click on "Launch Instance".
4. Configure instance details:
   - Instance Name: EFS-1
5. Choose an Amazon Machine Image (AMI) for Linux.
6. Select instance type: t2.micro.
   - Key Pair: EFS
   - Network: Choose Subnet-1a
   - Security Group: Create a new security group (SG) and add NFS and allow from anywhere.
7. Launch the instance.
8. Repeat the above steps to launch another instance named EFS-2 in Subnet-1b with the same configuration.
Step 2: Creating an EFS File System
1. Go to the EFS service in the AWS Management Console.
2. Click on "Create file system".
3. Specify details:
   - Name: Optional
   - VPC: Default
   - Enable region button.
Click on "Next".
4. In the Network settings:
   - Delete all security groups.
   - Select the newly created security group (NFS).---which is created while creating instance
 Click on "Next" and review the configuration.
Click on "Create file system".
Step 3: Accessing the two EC2 instances named EFS-1 & EFS -2 in two different PowerShell sessions and performing the specified tasks:
Accessing EFS-1 Instances in Two Different PowerShell Sessions:
1. Open Two PowerShell Sessions:
   - Open two separate PowerShell windows or tabs on your local machine.
For each  Instance:
2. SSH into the Instance:
   - Use the SSH command to connect to the EFS-1 instance
          ssh -i [path-to-your-keypair.pem] ec2-user@[instance-public-ip]
3. Switch to Root User:
   - Gain root access by executing the following command:
         sudo su
    4. Create a Directory:
   - Make a directory named "efs" using the following command:
          mkdir efs
     5. Install Amazon EFS Utilities:
   - Use yum package manager to install the Amazon EFS utilities:
         yum install -y amazon-efs-utils
     6. List Files:
   - Execute the following command to list files in the current directory:
          ls
     7. Verify Installation (Optional):
   - Optionally, you can verify the installation of the Amazon EFS utilities by checking the version:
         efs-utils --version
     Repeat Steps 2-7 for -------------------------  EFS-2 Instance.
By following these steps, you'll have accessed each EFS-1 instance in separate PowerShell sessions, switched to the root user, created a directory named "efs," installed the Amazon EFS utilities, and listed files in the directory. This setup allows you to configure and manage each instance individually as needed.
Step 4: Attaching EFS to EC2 Instances
1. Go to the EFS service in the AWS Management Console.
2. Click on the target EFS file system.
3. Click on the "Attach" button.
4. Choose "Mount via DNS" option.
5. Copy the displayed command. ,on both ec2 instances(powershell)
6. Paste and execute the copied command in the terminal to mount the EFS file system onto the instance.
Step 5: Verify and Test EFS
1. Change the directory to EFS on both instances.
2. Create a file on one instance.
3. Verify that the file automatically synchronizes and appears on the other instance.

By above steps, we can successfully create EC2 instances, configured them, created an EFS file system, and attached it to the instances in the same availability zone in the Mumbai region. Now, the instances can seamlessly access and share files stored in the EFS file system.






EXPERIMENT 4 S3


Simple Storage Service (S3)
 1.  Versioning: Versioning in Amazon S3 is a feature that allows you to keep multiple versions of an object in the same bucket. Whenever you upload a new version of an object with the same key (name) as an existing object, S3 doesn't overwrite the existing object but instead creates a new version of it. This means you can retain and access previous versions of objects, providing an additional layer of protection against accidental deletions or overwrites
i.	Accidental Deletion Protection :: With versioning enabled, if you accidentally delete an object, you can still retrieve previous versions of it, preventing data loss.
ii.	Accidental Overwrite Protection::Versioning prevents accidental overwrites of objects. Even if you upload a new version of an object with the same name, the previous versions are preserved.
 
1.	Cross-Region Replication: Cross-region replication (CRR) in Amazon S3 is a feature that automatically replicates objects from one bucket in one AWS region to another bucket in a different AWS region. This provides redundancy and disaster recovery capabilities, ensuring that your data remains available even if an entire AWS region becomes unavailable.
i.	Disaster Recovery: Cross-region replication helps ensure business continuity by replicating critical data to a different geographic region, reducing the risk of data loss due to regional disasters or outages.
ii.	Low-Latency Access: Users in different geographic regions can access data from the nearest region, reducing latency and improving performance.
iii.	Compliance: Some regulatory requirements mandate data replication across multiple geographic regions for data sovereignty and compliance reasons.
2.	Event Notifications: S3 can trigger events (e.g., object creation, deletion) that can be routed to AWS Lambda, SNS, or SQS for processing.
3.	Integration: S3 seamlessly integrates with other AWS services such as AWS Lambda, Amazon CloudFront, AWS Glue, Amazon Athena, and Amazon EMR, enabling you to build powerful data processing and analytics workflows.


 

________________________________________
1.Creating an S3 bucket, upload an object, and enable public access 
1Ô∏è‚É£ Create an S3 Bucket (with Public Access Enabled)
Step 1: Open S3 Service
‚Ä¢	Login to AWS Management Console
‚Ä¢	Go to Services ‚Üí S3
‚Ä¢	Click Create bucket
________________________________________
Step 2: Bucket Configuration
‚Ä¢	Bucket name: my-public-bucket-123
‚Ä¢	Region: Choose nearest region
________________________________________
Step 3: Disable Block Public Access (IMPORTANT)
Under Block Public Access settings for this bucket:
‚ùå Uncheck Block all public access
You must uncheck ALL options:
‚úî Check I acknowledge that this bucket will become public
üëâ Click Create bucket
________________________________________
2Ô∏è‚É£ Enable Public Access at Bucket Level (ACL)
Step 4: Open the Bucket
‚Ä¢	Click on the bucket name
‚Ä¢	Go to Permissions tab
________________________________________
Step 5: Edit Bucket ACL
‚Ä¢	Scroll to Access Control List (ACL)
‚Ä¢	Click Edit
Under Public access:
‚Ä¢	Everyone (public access) ‚Üí ‚úî Read access
‚úî Save changes
üìå This allows public access at bucket level
________________________________________
3Ô∏è‚É£ Upload Object to the Bucket
Step 6: Upload File
‚Ä¢	Go to Objects tab
‚Ä¢	Click Upload
‚Ä¢	Click Add files
‚Ä¢	Select file (e.g., image.jpg)
‚Ä¢	Click Upload
________________________________________
4Ô∏è‚É£ Enable Public Access for Object (ACL)
Step 7: Object-Level ACL Permission
‚Ä¢	Click on uploaded object
‚Ä¢	Go to Permissions tab
‚Ä¢	Scroll to Access Control List (ACL)
‚Ä¢	Click Edit
Under Public access:
‚Ä¢	Everyone (public access) ‚Üí ‚úî Read access
‚úî Save changes
________________________________________
5Ô∏è‚É£ Verify Public Access
Step 8: Test Object URL
‚Ä¢	Copy Object URL
‚Ä¢	Open in browser (incognito)
‚úî Object should be accessible without login
________________________________________
2. S3 Versioning & Cross-Region Replication 
________________________________________
1Ô∏è‚É£ Enabling Versioning in S3 (with Output Scenario)
üî∏ Objective
To enable version control on an S3 bucket and observe object versions.
________________________________________
üî∏ Steps to Enable Versioning
1.	Open AWS Management Console
2.	Navigate to S3
3.	Select the bucket
4.	Go to Properties tab
5.	Scroll to Bucket Versioning
6.	Click Edit
7.	Select Enable
8.	Click Save changes
‚úî Versioning is now enabled
________________________________________
üî∏ Output Scenario (What You Observe)
Step A: Upload Object
‚Ä¢	Upload file: report.pdf
üìå Output:
‚Ä¢	Version ID is assigned automatically
________________________________________
Step B: Modify and Re-upload Same Object
‚Ä¢	Upload report.pdf again (same name)
üìå Output:
‚Ä¢	Old version is preserved
‚Ä¢	New version becomes current
________________________________________
Step C: Delete Object
‚Ä¢	Click Delete on report.pdf
üìå Output:
‚Ä¢	Object appears deleted
‚Ä¢	A Delete Marker is created
‚Ä¢	Older versions still exist and can be restored
________________________________________

2Ô∏è‚É£ Cross-Region Replication (CRR) 
üî∏ Objective
To replicate objects from one bucket to another in a different region using AWS-managed permissions.
________________________________________
üî∏ Prerequisites (Very Important)
‚úî Versioning must be enabled on both buckets
‚úî Source and destination buckets must be in different regions
‚úî AWS Academy automatically handles replication permissions
________________________________________
Step 1Ô∏è‚É£ Create Destination Bucket
1.	Go to S3 ‚Üí Create bucket
2.	Bucket name: dest-crr-bucket
3.	Select different region
4.	Complete bucket creation
5.	Enable Versioning (same steps as above)
________________________________________
Step 2Ô∏è‚É£ Create Replication Rule (Without IAM Selection)
1.	Open Source bucket
2.	Go to Management tab
3.	Click Replication rules
4.	Click Create replication rule
________________________________________
Step 3Ô∏è‚É£ Configure Replication Rule
‚Ä¢	Rule name: academy-crr-rule
‚Ä¢	Status: Enabled
‚Ä¢	Scope: Apply to all objects
________________________________________
Step 4Ô∏è‚É£ Choose Destination Bucket
‚Ä¢	Select Another bucket
‚Ä¢	Choose Destination bucket
‚Ä¢	Confirm different region
üìå AWS Academy Note:
You will see an option like:
"AWS will create and manage the required permissions automatically"
‚úî Select Use AWS-managed role / default role
________________________________________
Step 5Ô∏è‚É£ Replication Options
‚Ä¢	Replicate:
o	‚úî New objects
o	‚ùå Existing objects (optional, depends on Academy permissions)
‚Ä¢	Encryption: Leave default
Click Save
‚úî Replication rule is now active
________________________________________
3Ô∏è‚É£ CRR Output Scenario (What You Observe)
üî∏ Step A: Upload New Object to Source Bucket
‚Ä¢	Upload file: image.png
üìå Output:
‚Ä¢	Object is uploaded normally
________________________________________
üî∏ Step B: Verify Destination Bucket
‚Ä¢	Open destination bucket
‚Ä¢	Object image.png appears automatically
‚Ä¢	Version ID is present
‚úî Replication successful
________________________________________

3.	Static Website Hosting in S3
(Using Bucket-Level & Object-Level Permissions ‚Äì ACL Method)
________________________________________
üîπ Objective
To host a static website in Amazon S3 using index.html and error.html, and allow public access using ACL-based bucket and object permissions.
________________________________________
üîπ Prerequisites
‚Ä¢	AWS / AWS Academy account
‚Ä¢	Two files:
o	index.html
o	error.html
________________________________________
1Ô∏è‚É£ Create an S3 Bucket
1.	Login to AWS Management Console
2.	Go to Services ‚Üí S3
3.	Click Create bucket
4.	Enter:
o	Bucket name: my-static-site-bucket-123
o	Region: Nearest region
5.	Under Block Public Access:
o	‚ùå Uncheck Block all public access
o	‚úî Acknowledge the warning
6.	Click Create bucket
‚úî Bucket created successfully
________________________________________
2Ô∏è‚É£ Upload Website Files
1.	Open the bucket
2.	Go to Objects tab
3.	Click Upload
4.	Click Add files
5.	Select:
o	index.html
o	error.html
6.	Click Upload
‚úî Files uploaded
________________________________________
3Ô∏è‚É£ Enable Static Website Hosting
1.	Go to Properties tab
2.	Scroll to Static website hosting
3.	Click Edit
4.	Select Enable
5.	Choose Host a static website
6.	Enter:
o	Index document: index.html
o	Error document: error.html
7.	Click Save changes
‚úî Static website hosting enabled
________________________________________
4Ô∏è‚É£ Enable Bucket-Level Public Access (ACL)
üîπ Purpose
Allows public users to access objects inside the bucket.
________________________________________
1.	Go to Permissions tab
2.	Scroll to Access Control List (ACL)
3.	Click Edit
4.	Under Public access:
o	Everyone (public access) ‚Üí ‚úî Read
5.	Click Save changes
‚úî Bucket-level public read access enabled
________________________________________
5Ô∏è‚É£ Enable Object-Level Public Access (ACL)
Steps (For Each File)
1.	Go to Objects tab
2.	Click on index.html
3.	Go to Permissions
4.	Scroll to Access Control List (ACL)
5.	Click Edit
6.	Under Public access:
o	Everyone (public access) ‚Üí ‚úî Read
7.	Save changes
üîÅ Repeat the same steps for error.html
‚úî Object-level public access enabled
________________________________________
6Ô∏è‚É£ Access the Static Website
1.	Go to Properties
2.	Scroll to Static website hosting
3.	Copy the Bucket website endpoint
4.	http://my-static-site-bucket-123.s3-website-region.amazonaws.com
5.	Paste into browser
‚úî index.html page loads successfully
________________________________________
7Ô∏è‚É£ Error Page Output Scenario
üîπ Test Error Page
‚Ä¢	Open an invalid URL:
‚Ä¢	http://bucket-name.s3-website-region.amazonaws.com/invalid.html
üìå Output:
‚Ä¢	error.html page is displayed
‚úî Error page working correctly




EXPERIMENT 5 VPC

Week 5: VPC Creation and Ec2 Instance Connection
üîπ Step 1: Create the VPC
1.	Go to AWS Management Console ‚Üí VPC
2.	Click Create VPC
3.	Choose VPC only
4.	Enter:
o	Name: Custom-VPC
o	IPv4 CIDR block: e.g. 10.0.0.0/16
5.	Click Create VPC
üîπ Step 2: Create Subnets (Public & Private)
Create subnets in same Availability Zones for high availability.
Example:
‚Ä¢	Public Subnet: 10.0.1.0/24 (AZ-A)
‚Ä¢	Private Subnet: 10.0.2.0/24 (AZ-A)
Steps:
1.	Go to Subnets ‚Üí Create subnet
2.	Select your VPC
3.	Choose AZ
4.	Enter CIDR
5.	Create subnet
üîπ Step 3: Create an Internet Gateway (IGW)
1.	Go to Internet Gateways
2.	Click Create internet gateway
3.	Name it Custom-IGW
4.	Attach it to your VPC
üîπ Step 4: Create Route Tables
You need separate route tables for public and private subnets.
Public Route Table
1.	Go to Route Tables ‚Üí Create route table
2.	Select VPC
3.	Add route:
o	Destination: 0.0.0.0/0
o	Target: Internet Gateway
4.	Associate with public subnet
Private Route Table
‚Ä¢	Keep default local route only (no IGW)
‚Ä¢	Associate with private subnet
üîπ Step 5: Enable Auto-Assign Public IP (Public Subnet)
1.	Select Public Subnet
2.	Go to Edit subnet settings
3.	Enable Auto-assign public IPv4 address
üîπ Step 6: Configure Security Groups
1.	Create a Security Group
2.	Add inbound rules:
o	HTTP (80) / HTTPS (443)
o	SSH (22) from trusted IP
3.	Attach to EC2 instances
üîπ Step 7: Launch EC2 Instances
‚Ä¢	Public EC2 ‚Üí Public subnet
‚Ä¢	Private EC2 ‚Üí Private subnet
Attach correct security groups.
üîπ Step 8: Test the Setup
‚Ä¢	Public EC2 ‚Üí Internet access ‚úî
‚Ä¢	Private EC2 ‚Üí Internet via NAT ‚úî
‚Ä¢	Private EC2 ‚Üí No direct inbound access ‚úî
